---
title: "Group Project 1 | STAT 330"

author: <center> Elizabeth Mohler, Peter Welty, Jeong Kim <center>
output: html_document
---

<style type="text/css">
h1.title {
  font-size: 40px;
  text-align: center;
}
</style>

```{r setup, include=FALSE}
# load any necessary packages here
library(tidyverse)
library(ggfortify)
library(car)
sz <- 16
```


## Data and Description

We are interested to see if there is a correlation between crime rates and average rent in a city in the United States. We hypothesize that rent with have a significant affect on crime rate, specifically that higher rent will increase crime. Our predictor variable is crime rate and how it might explain rent prices in a city.

To test our assumption, we got our crime data from the FBI's database from 2010-2015 and got our rent data for the same years from Zillow. We will begin our analysis by applying basic summary statistics and exploratory data techniques to better understand the data. Then, we apply simple linear regression

We conclude our analysis by using what we learned to infer to ... We recommend ...

## Steps

### Import and preprocessing data

The following table displays the variable names in this data set, along with their descriptions.

Variable   | Description
---------- | -------------
Weight     | Weight of the car in pounds
MPG        | Miles per gallon of the car

```{r}
data <- read.csv(file = "Crime_vs_Rent_Group_Project.csv", header = TRUE)
```

#### Preprocessing
- Originally, there are two datasets. One for rent and one for crime. We merged them. 
- Remove NaNs in Avg_rent and crime_rate columns
```{r}
data <- data[!is.na(data$Avg_rent), ]
data <- data[!is.na(data$crime_rate),]
```


We start by applying basic summary and exploratory statistics to this data to better understand the data and identify trends.

```{r}
summary(data)
head(data)
```

```{r}
glimpse(data)
```

#### Correlation

```{r}
cor(data$Avg_rent, data$crime_rate)
```

```{r}
data.lm <- lm(formula = crime_rate ~ Avg_rent, data = data)
summary(data.lm)

data$residuals <- data.lm$residuals
data$fitted.values <- data.lm$fitted.values
```

### Basic Scatterplot
```{r}
data.base.plot <- ggplot(data = data, mapping = aes(x = Avg_rent, y = crime_rate)) + 
  geom_point() +
  ggtitle("Title") +
  xlab("Average Rent ($)") +
  ylab("Crime Rate") +
  scale_x_continuous(breaks = seq(0, 4000, by = 500),
                     minor_breaks = seq(0, 4000, by = 500)) +
  scale_y_continuous(breaks = seq(0, 0.025, by = 0.0025),
                     minor_breaks = seq(0, 0.025, by = 0.0025)) +
  theme(aspect.ratio = 1, plot.title = element_text(hjust = 0.5))
data.base.plot
```

The OLS regression line along with the scatterplot

```{r}
data.base.plot + geom_smooth(method = "lm", se = FALSE) 
```

Residuals vs. Fitted Values Plot

```{r}
autoplot(data.lm, which = 1, ncol = 1, nrow = 1) +
  theme(aspect.ratio = 1, plot.title = element_text(hjust = 0.5))
```

Residuals vs. Predictor Plot

```{r}
ggplot(data = data, mapping = aes(y = residuals, x = Avg_rent)) +
  geom_point() +
  theme(aspect.ratio = 1)
```



Normal Probability Plot

```{r}
autoplot(data.lm, which = 2, ncol = 1, nrow = 1) +
  theme(aspect.ratio = 1, plot.title = element_text(hjust = 0.5))
```

Histogram for residuals

```{r}
ggplot(data = data, mapping = aes(x = residuals)) + 
  geom_histogram(mapping = aes(y = ..density..), binwidth = 0.0015) +
  stat_function(fun = dnorm, color = "red", size = 2,
                args = list(mean = mean(data$residuals), 
                            sd = sd(data$residuals))) +
  theme(aspect.ratio = 1)
```

Boxplot for residuals

```{r}
ggplot(data = data, mapping = aes(y = residuals)) +
  geom_boxplot() +
  theme(aspect.ratio = 1)
```

Sequence Plot

```{r}
ggplot(data) +
  geom_line(mapping = aes(x = 1:dim(data)[1], y = residuals)) +
  theme_bw() + 
  scale_y_continuous(limits = c(-0.008, 0.015)) +
  scale_x_continuous(limits = c(0, 350)) +
  xlab("TODO") +
  theme(axis.title.x = element_text(size = sz),
        axis.title.y = element_text(size = sz),
        axis.text = element_text(size = sz),
        aspect.ratio = 1)
```

Shapiro-Wilk Test

```{r}
shapiro.test(data$residuals)
```

Cook's Distance

```{r}
data$cooksd <- cooks.distance(data.lm)
# Find n
data[data$cooksd >= 4 / length(data$cooksd), ]
```

Brown-Forsythe Test

```{r}
grp <- as.factor(c(rep("lower", floor(dim(data)[1] / 2)), 
                   rep("upper", ceiling(dim(data)[1] / 2))))
leveneTest(data[order(data$Avg_rent), "residuals"] ~ grp, center = median)
```

DFBETAS

```{r}
# calculate the DFBETAS
data.dfbetas <- as.data.frame(dfbetas(data.lm))
# add the observation numbers to dataframe for plotting purposes
data.dfbetas$obs <- 1:length(data$Avg_rent)

# plot the DFBETAS against the observation number
ggplot(data = data.dfbetas) + 
  geom_point(mapping = aes(x = obs, y = abs(Avg_rent))) +
  ylab("Absolute Value of DFBETAS for Average Rent") +
  xlab("Observation Number") +
  geom_hline(mapping = aes(yintercept = 2 / sqrt(length(obs))),
             color = "red", linetype = "dashed") +
  #scale_x_continuous(limits = c(0, 300)) +
  #scale_y_continuous(limits = c(0, 0.25)) +
  theme_bw() +
  theme(
    axis.title.x = element_text(size = sz - 5),
    axis.title.y = element_text(size = sz - 5),
    axis.text = element_text(size = sz - 5),
    aspect.ratio = 1,
    plot.title = element_blank()
  )

# print a list of potential influential points according to DFBETAS
rent.extreme.dfbetas <- data.dfbetas[abs(data.dfbetas$Avg_rent) > 
                                         2 / sqrt(length(data.dfbetas$obs)), ]
rent.extreme.dfbetas[order(rent.extreme.dfbetas$Avg_rent), ]
```

DFFITS

```{r}
# calculate the DFFITS
data.dffits <- data.frame("dffits" = dffits(data.lm))
# add the observation numbers to dataframe for plotting purposes
data.dffits$obs <- 1:length(data$crime_rate)

# plot the DFFITS against the observation number
ggplot(data = data.dffits) + 
  geom_point(mapping = aes(x = obs, y = abs(dffits))) +
  ylab("Absolute Value of DFFITS for Y") +
  xlab("Observation Number") +
  geom_hline(mapping = aes(yintercept = 2 * 
                             sqrt(length(data.lm$coefficients) / length(obs))),
             color = "red", linetype = "dashed") +
  theme_bw() +
  #scale_x_continuous(limits = c(0, 300)) +
  #scale_y_continuous(limits = c(0, 0.3)) +
  theme(
    axis.title.x = element_text(size = sz - 5),
    axis.title.y = element_text(size = sz - 5),
    axis.text = element_text(size = sz - 5),
    aspect.ratio = 1,
    plot.title = element_blank()
  )

# print a list of potential influential points according to DFFITS
data.dffits[abs(data.dffits$dffits) > 2 * 
             sqrt(length(data.lm$coefficients) / length(data.dffits$obs)), ]
```




### Assumptions

#### X vs Y is linear
X vs Y is not linear, since the scatterplot does not look roughly linear and does not look like a line can be easily fitted to the data. As well the Residuals vs Fitted values plot shows that the blue line is not roughly horizontal with heavy curvature. 

#### The residuals are independent

The residuals seem not to be independent since crimes the recorded are only observed or reported to the FBI. Crime in general is not random but premeditated. However, average rent is more likely to be skewed by heavy outliers in cities depending on the area. Median rent prices might be a better indicator.

#### The residuals are normally distributed and centered at zero

The residuals are not normally distributed. The box plot is pretty right skewed with the mean not centered at zero with the whiskers having very different lengths. As well the right skew is found in the density and residual histogram. Lastly the shapiro-wilk tests gives us a very small and significant p-value less than 0.05 therefore we reject the null hypothesis that the residuals are normally distrubuted.

#### The residuals have equal/constant variance across all values of X

The residuals do  have equal/constant variance across all values of average rent. The residuals vs fitted values plot seems to show equal variance of average rent prices with slightly more variance on the right side . However, the brown-forsythe test gives us a non-significant p-value of 0.8168 which is greater than 0.05. Therefore we fail to reject the null hypothesis that the redisuals have equal variance across all values of average rent prices. 

#### The model describes all observations (i.e., there are no influential points)

The model seems to describe all observations, since the boxplot shows only about 4 outliers. The histogram shows possible a couple outliers. The Q-Q plot shows the same. However, the cooks distance shows many observation greater than 4/335 but they are pretty close to this cut-off. There is only one that seems to be significantly far from the cutoff and very unlikely to be influential due to the amount of observations. 

#### Additional predictor variables are not required.

Additional predictor variables may actually be required. Since it seems rent prices do not predict crime rates very well. Other predictor variables may be supply vs demand of housing in a city or State. Another predictor could be numbers of years since last renovations of housing. As well unemployment rates in a city could possibly predict crime rates.

### A Preliminary Conclusion
 Simple linear regression is not appropriate for this data set since few assumptions are met to even justify it. Another big indicator is the presence of many other predictor variables that could influence crime rates. Therefore it is possible that even transforming the current model may not yield any compelling results. It seems that Multiple linear regression could be a better route to be able to predict crime-rates. Trying to make statistical inference on this current model will mostly likely reveal that this is the case. 


```{r, fig.align='center'}
# We need to transform our data, so we run a Box Cox
bc <- boxCox(data$Avg_rent ~ data$crime_rate)

data$rent_transformed <- sin(data$Avg_rent)
data$crime_transformed <- log(log((data$crime_rate) ^ (-4/3)))



```
### Choosing a Tranformation
We knew we needed to tranform y (crime rate) significantly because the residuals were all over the place. We performed a box cox and saw the data was improving, but we then took the log of the transformed data, and it helped out nicely. We also transformed x which helped with normality in the data set. 


```{r}
transformed_data.lm <- lm(formula = crime_transformed ~ rent_transformed, data = data)
summary(transformed_data.lm)

data$residuals_t <- transformed_data.lm$residuals
data$fitted.values_t <- transformed_data.lm$fitted.values
```

### Basic Scatterplot
```{r}
data.transformed.plot <- ggplot(data = data, mapping = aes(x = rent_transformed, y = crime_rate)) + 
  geom_point() +
  ggtitle("Tranformed Data Scatterplot") +
  xlab("sin(Average Rent) ($)") +
  ylab("log(1 /Crime Rate ^4/3)") +
  scale_x_continuous(breaks = seq(0, 4000, by = 500),
                     minor_breaks = seq(0, 4000, by = 500)) +
  scale_y_continuous(breaks = seq(0, 0.025, by = 0.0025),
                     minor_breaks = seq(0, 0.025, by = 0.0025)) +
  theme(aspect.ratio = 1, plot.title = element_text(hjust = 0.5))
data.transformed.plot
```

The OLS regression line along with the scatterplot

```{r}
data.transformed.plot + geom_smooth(method = "lm", se = FALSE) 
```

Residuals vs. Fitted Values Plot

```{r}
autoplot(transformed_data.lm, which = 1, ncol = 1, nrow = 1) +
  theme(aspect.ratio = 1, plot.title = element_text(hjust = 0.5))
```

Residuals vs. Predictor Plot

```{r}
ggplot(data = data, mapping = aes(y = residuals_t, x = rent_transformed)) +
  geom_point() +
  theme(aspect.ratio = 1)
```



Normal Probability Plot

```{r}
autoplot(transformed_data.lm, which = 2, ncol = 1, nrow = 1) +
  theme(aspect.ratio = 1, plot.title = element_text(hjust = 0.5))
```

Histogram for residuals

```{r}
ggplot(data = data, mapping = aes(x = residuals_t)) + 
  geom_histogram(mapping = aes(y = ..density..), binwidth = .05) +
  stat_function(fun = dnorm, color = "red", size = 2,
                args = list(mean = mean(data$residuals_t), 
                            sd = sd(data$residuals_t))) +
  theme(aspect.ratio = 1)
```

Boxplot for residuals

```{r}
ggplot(data = data, mapping = aes(y = residuals_t)) +
  geom_boxplot() +
  theme(aspect.ratio = 1)
```

Sequence Plot

```{r}
ggplot(data) +
  geom_line(mapping = aes(x = 1:dim(data)[1], y = residuals_t)) +
  theme_bw() + 
  scale_y_continuous(limits = c(-.5,.5)) +
  scale_x_continuous(limits = c(0,340)) +
  xlab("TODO") +
  theme(axis.title.x = element_text(size = sz),
        axis.title.y = element_text(size = sz),
        axis.text = element_text(size = sz),
        aspect.ratio = 1)
```

Shapiro-Wilk Test

```{r}
shapiro.test(data$residuals_t)
```

Cook's Distance

```{r}
data$cooksd_t <- cooks.distance(transformed_data.lm)
# Find n
data[data$cooksd_t >= 4 / length(data$cooksd_t), ]
```

Brown-Forsythe Test

```{r}
grp <- as.factor(c(rep("lower", floor(dim(data)[1] / 2)), 
                   rep("upper", ceiling(dim(data)[1] / 2))))
leveneTest(data[order(data$rent_transformed), "residuals"] ~ grp, center = median)
```

DFBETAS

```{r}
# calculate the DFBETAS
data.dfbetas_t <- as.data.frame(dfbetas(transformed_data.lm))
# add the observation numbers to dataframe for plotting purposes
data.dfbetas_t$obs <- 1:length(data$rent_transformed)

# plot the DFBETAS against the observation number
ggplot(data = data.dfbetas_t) + 
  geom_point(mapping = aes(x = obs, y = abs(rent_transformed))) +
  ylab("Absolute Value of DFBETAS for 1 / Average Rent") +
  xlab("Observation Number") +
  geom_hline(mapping = aes(yintercept = 2 / sqrt(length(obs))),
             color = "red", linetype = "dashed") +
  #scale_x_continuous(limits = c(0, 300)) +
  #scale_y_continuous(limits = c(0, 0.25)) +
  theme_bw() +
  theme(
    axis.title.x = element_text(size = sz - 5),
    axis.title.y = element_text(size = sz - 5),
    axis.text = element_text(size = sz - 5),
    aspect.ratio = 1,
    plot.title = element_blank()
  )

# print a list of potential influential points according to DFBETAS
rent.extreme.dfbetas_t <- data.dfbetas_t[abs(data.dfbetas_t$rent_transformed) > 
                                         2 / sqrt(length(data.dfbetas_t$obs)), ]
rent.extreme.dfbetas_t[order(rent.extreme.dfbetas_t$rent_transformed), ]
```

DFFITS

```{r}
# calculate the DFFITS
data.dffits_t <- data.frame("dffits" = dffits(transformed_data.lm))
# add the observation numbers to dataframe for plotting purposes
data.dffits_t$obs <- 1:length(data$crime_rate)

# plot the DFFITS against the observation number
ggplot(data = data.dffits_t) + 
  geom_point(mapping = aes(x = obs, y = abs(dffits))) +
  ylab("Absolute Value of DFFITS for Y") +
  xlab("Observation Number") +
  geom_hline(mapping = aes(yintercept = 2 * 
                             sqrt(length(transformed_data.lm$coefficients) / length(obs))),
             color = "red", linetype = "dashed") +
  theme_bw() +
  #scale_x_continuous(limits = c(0, 300)) +
  #scale_y_continuous(limits = c(0, 0.3)) +
  theme(
    axis.title.x = element_text(size = sz - 5),
    axis.title.y = element_text(size = sz - 5),
    axis.text = element_text(size = sz - 5),
    aspect.ratio = 1,
    plot.title = element_blank()
  )

# print a list of potential influential points according to DFFITS
data.dffits[abs(data.dffits_t$dffits) > 2 * 
             sqrt(length(transformed_data.lm$coefficients) / length(data.dffits_t$obs)), ]
```

A 95% confidence interval for the slope

```{r}
confint(transformed_data.lm, parm = "rent_transformed", level = 0.95)
```
We are 95% confident that the average [Transformed y] increases between -.045 and .005 for every one increase in the sin of rent?
Because zero is concluding in this interval, we fail to reject the null and cannot say whether or not there is a relationship between rent and crime rate. 


The MSE

```{r}
sum(data$residuals_t ^ 2) / (length(data$residuals_t) - 2)
```

```{r}
summary(transformed_data.lm)$r.squared
summary(transformed_data.lm)$adj.r.squared
summary(transformed_data.lm)$fstatistic

```

```{r}


```



## Results and Conclusion



